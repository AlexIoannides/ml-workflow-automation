{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Model Deployment\n",
    "\n",
    "The purpose of this notebook is to demonstrate how the model yielded by `titanic-ml.ipynb` can be deployed as a RESTful service on Kubernetes.\n",
    "\n",
    "Required steps:\n",
    "\n",
    "1. inject model into a Flask service:\n",
    "    - create 'deploy' directory;\n",
    "    - 'download' model locally;\n",
    "    - 'download' Flask model wrapper;\n",
    "    - use environment variable to pass model name to Flask service;\n",
    "2. inject Flask service into Docker container:\n",
    "    - build Docker image;\n",
    "    - push image to registry;\n",
    "3. deploy end-to-end service to Kubernetes using a Helm chart:\n",
    "    - download the appropriate Helm chart;\n",
    "    - set the appropriate parameter values for service naming, clusters, etc.; and,\n",
    "    - deploy using Helm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mandatory Deployment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'models/titanic-ml-2019-02-11T17:48:28.joblib'\n",
    "SERVICE_NAME = 'titanic'\n",
    "API_VERSION = '1'\n",
    "DOCKER_IMAGE_REGISTRY = 'alexioannides'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy Model to `py-flask-ml-service`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = os.popen(f'cp {MODEL} deploy/py-flask-ml-service/model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy `Pipfile` ?\n",
    "\n",
    "- how to best manage the needs of the service with the needs of the notebook?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Service Parameters to `.env` File in `py-flask-ml-service`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('deploy/py-flask-ml-service/.env', 'w') as file:\n",
    "    file.writelines(f'SERVICE_NAME={SERVICE_NAME}\\n')\n",
    "    file.writelines(f'API_VERSION={API_VERSION}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate the contents of the `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SERVICE_NAME=titanic\n",
      "API_VERSION=1\n"
     ]
    }
   ],
   "source": [
    "!cat deploy/py-flask-ml-service/.env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Docker Image\n",
    "\n",
    "- Note, we will need a build server (e.g. Travis) to build and push."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stream': 'Step 1/7 : FROM python:3.7-slim'}\n",
      "{'stream': '\\n'}\n",
      "{'stream': ' ---> 12c44ed85032\\n'}\n",
      "{'stream': 'Step 2/7 : WORKDIR /usr/src/app'}\n",
      "{'stream': '\\n'}\n",
      "{'stream': ' ---> Using cache\\n'}\n",
      "{'stream': ' ---> 987983ee8d98\\n'}\n",
      "{'stream': 'Step 3/7 : COPY . .'}\n",
      "{'stream': '\\n'}\n",
      "{'stream': ' ---> Using cache\\n'}\n",
      "{'stream': ' ---> 69c4a130e3a3\\n'}\n",
      "{'stream': 'Step 4/7 : EXPOSE 5000'}\n",
      "{'stream': '\\n'}\n",
      "{'stream': ' ---> Using cache\\n'}\n",
      "{'stream': ' ---> 4dc4b5889146\\n'}\n",
      "{'stream': 'Step 5/7 : RUN pip install pipenv'}\n",
      "{'stream': '\\n'}\n",
      "{'stream': ' ---> Using cache\\n'}\n",
      "{'stream': ' ---> 6fc75cdd7a31\\n'}\n",
      "{'stream': 'Step 6/7 : RUN pipenv install'}\n",
      "{'stream': '\\n'}\n",
      "{'stream': ' ---> Using cache\\n'}\n",
      "{'stream': ' ---> c92bf05cb214\\n'}\n",
      "{'stream': 'Step 7/7 : ENTRYPOINT [\"pipenv\", \"run\", \"python\", \"api.py\"]'}\n",
      "{'stream': '\\n'}\n",
      "{'stream': ' ---> Using cache\\n'}\n",
      "{'stream': ' ---> 7e720856dd7b\\n'}\n",
      "{'aux': {'ID': 'sha256:7e720856dd7bad13b682008acad5c5fed42fa6d54243fe8097472918af45929d'}}\n",
      "{'stream': 'Successfully built 7e720856dd7b\\n'}\n",
      "{'stream': 'Successfully tagged alexioannides/titanic:latest\\n'}\n"
     ]
    }
   ],
   "source": [
    "image_tag = f'{DOCKER_IMAGE_REGISTRY}/{SERVICE_NAME}:latest'\n",
    "\n",
    "docker_client = docker.from_env()\n",
    "image, build_log = docker_client.images.build(\n",
    "    path='deploy/py-flask-ml-service', tag=image_tag, rm=True)\n",
    "\n",
    "for line in build_log:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push Image to DockerHub\n",
    "\n",
    "- Will need to use `docker_client.login()` on a build server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"status\":\"The push refers to repository [docker.io/alexioannides/titanic]\"}\n",
      "{\"status\":\"Preparing\",\"progressDetail\":{},\"id\":\"be5e43672981\"}\n",
      "{\"status\":\"Preparing\",\"progressDetail\":{},\"id\":\"e8b2176335b2\"}\n",
      "{\"status\":\"Preparing\",\"progressDetail\":{},\"id\":\"c15578014699\"}\n",
      "{\"status\":\"Preparing\",\"progressDetail\":{},\"id\":\"f49f129dd410\"}\n",
      "{\"status\":\"Preparing\",\"progressDetail\":{},\"id\":\"be1cb44a8fa5\"}\n",
      "{\"status\":\"Preparing\",\"progressDetail\":{},\"id\":\"94a02319f331\"}\n",
      "{\"status\":\"Preparing\",\"progressDetail\":{},\"id\":\"c22eb8781541\"}\n",
      "{\"status\":\"Preparing\",\"progressDetail\":{},\"id\":\"622d7e308e90\"}\n",
      "{\"status\":\"Preparing\",\"progressDetail\":{},\"id\":\"0a07e81f5da3\"}\n",
      "{\"status\":\"Waiting\",\"progressDetail\":{},\"id\":\"94a02319f331\"}\n",
      "{\"status\":\"Waiting\",\"progressDetail\":{},\"id\":\"c22eb8781541\"}\n",
      "{\"status\":\"Waiting\",\"progressDetail\":{},\"id\":\"622d7e308e90\"}\n",
      "{\"status\":\"Waiting\",\"progressDetail\":{},\"id\":\"0a07e81f5da3\"}\n",
      "{\"status\":\"Layer already exists\",\"progressDetail\":{},\"id\":\"f49f129dd410\"}\n",
      "{\"status\":\"Layer already exists\",\"progressDetail\":{},\"id\":\"c15578014699\"}\n",
      "{\"status\":\"Layer already exists\",\"progressDetail\":{},\"id\":\"be1cb44a8fa5\"}\n",
      "{\"status\":\"Layer already exists\",\"progressDetail\":{},\"id\":\"be5e43672981\"}\n",
      "{\"status\":\"Layer already exists\",\"progressDetail\":{},\"id\":\"e8b2176335b2\"}\n",
      "{\"status\":\"Layer already exists\",\"progressDetail\":{},\"id\":\"0a07e81f5da3\"}\n",
      "{\"status\":\"Layer already exists\",\"progressDetail\":{},\"id\":\"622d7e308e90\"}\n",
      "{\"status\":\"Layer already exists\",\"progressDetail\":{},\"id\":\"94a02319f331\"}\n",
      "{\"status\":\"Layer already exists\",\"progressDetail\":{},\"id\":\"c22eb8781541\"}\n",
      "{\"status\":\"latest: digest: sha256:62a651d4eadf47a370388ae5b3678aaea7d9f96a19a7368c16f0f11b82b14aeb size: 2213\"}\n",
      "{\"progressDetail\":{},\"aux\":{\"Tag\":\"latest\",\"Digest\":\"sha256:62a651d4eadf47a370388ae5b3678aaea7d9f96a19a7368c16f0f11b82b14aeb\",\"Size\":2213}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "push_log = docker_client.images.push(image_tag)\n",
    "print(push_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy to Kubernetes using Helm Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME:   xrayed-olm\n",
      "LAST DEPLOYED: Wed Feb 13 00:11:58 2019\n",
      "NAMESPACE: default\n",
      "STATUS: DEPLOYED\n",
      "\n",
      "RESOURCES:\n",
      "==> v1/Namespace\n",
      "NAME     STATUS  AGE\n",
      "titanic  Active  0s\n",
      "\n",
      "==> v1/Service\n",
      "NAME                            TYPE          CLUSTER-IP     EXTERNAL-IP  PORT(S)         AGE\n",
      "titanic-survival-prediction-lb  LoadBalancer  10.98.211.202  <pending>    5000:30438/TCP  0s\n",
      "\n",
      "==> v1/ReplicationController\n",
      "NAME                            DESIRED  CURRENT  READY  AGE\n",
      "titanic-survival-prediction-rc  2        2        0      0s\n",
      "\n",
      "==> v1/Pod(related)\n",
      "NAME                                  READY  STATUS             RESTARTS  AGE\n",
      "titanic-survival-prediction-rc-bsr8f  0/1    ContainerCreating  0         0s\n",
      "titanic-survival-prediction-rc-x74ph  0/1    ContainerCreating  0         0s\n",
      "\n",
      "\n",
      "NOTES:\n",
      "Thank you for installing helm-ml-score-app.\n",
      "\n",
      "Your release is named xrayed-olm.\n",
      "\n",
      "To learn more about the release, try:\n",
      "\n",
      "  $ helm status xrayed-olm\n",
      "  $ helm get xrayed-olm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!helm install deploy/helm-ml-prediction-app \\\n",
    "    --set app.name=\"$SERVICE_NAME-survival-prediction\" \\\n",
    "    --set app.namespace=\"$SERVICE_NAME\" \\\n",
    "    --set app.image=\"$image_tag\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Prediction Service\n",
    "\n",
    "We will assume that Minikube is being used for local testing, in which case we will need to ask it for the URL of its 'virtual load balancer' used for our service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-------------|--------------------------------|-----------------------------|\n",
      "|  NAMESPACE  |              NAME              |             URL             |\n",
      "|-------------|--------------------------------|-----------------------------|\n",
      "| default     | kubernetes                     | No node port                |\n",
      "| kube-system | kube-dns                       | No node port                |\n",
      "| kube-system | kubernetes-dashboard           | No node port                |\n",
      "| kube-system | tiller-deploy                  | No node port                |\n",
      "| titanic     | titanic-survival-prediction-lb | http://192.168.99.114:30438 |\n",
      "|-------------|--------------------------------|-----------------------------|\n"
     ]
    }
   ],
   "source": [
    "!minikube service list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then take the appropriate URL from the above and test our titanic prediction service!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"prediction\":[1]}\n"
     ]
    }
   ],
   "source": [
    "!curl http://192.168.99.114:30438/titanic/v1/predict \\\n",
    "        --request POST\\\n",
    "        --header 'Content-Type: application/json' \\\n",
    "        --data '{\"Pclass\": [1], \"Sex\": [\"male\"], \"Age\": [32], \"SibSp\": [1],                      \"Parch\": [0], \"Fare\": [100], \"Embarked\": [\"S\"]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
