{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Machine Learning Model\n",
    "\n",
    "This notebook contains a **quick** attempt at building a machine learning model for predicting the surival of a passenger on the ship [Titanic](https://en.wikipedia.org/wiki/RMS_Titanic), based on the dataset hosted at [Kaggle](https://www.kaggle.com). The ultimate aim of this work is to demonstrate an archytypal 'data science workflow' that includes some data exploration, feature engineering, model training and selection and to yield a model that can be used in other projects downstream. We have already downloaded the data from Kaggle, in CSV format, to the `data` directory in this project's root directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Imports and Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from datetime import datetime\n",
    "from typing import Any, Callable, Dict, Iterable\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from numpy import ndarray\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingClassifier, RandomForestClassifier, VotingClassifier)\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import (\n",
    "    BaseCrossValidator, GridSearchCV, StratifiedKFold, train_test_split)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/train.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics for Numeric Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data\n",
    " .drop(['PassengerId'], axis=1)\n",
    " .describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "- `Survived` - Survival (0 = No, 1 = Yes);\n",
    "- `Pclass` - Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd);\n",
    "- `Sex` - sex (male/female);\n",
    "- `SibSp` - # of siblings / spouses aboard the Titanic (positive integer);\n",
    "- `Parch` - # of parents / children aboard the Titanic (positive integer);\n",
    "- `Ticket` - Ticket number (positive integer);\n",
    "- `Fare` - Passenger fare (positive real);\n",
    "- `Cabin` - Cabin number (string); and,\n",
    "- `Embarked` - Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton).\n",
    "\n",
    "Note, that some children travelled only with a nanny, therefore `parch=0` for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Class Labels\n",
    "\n",
    "The class labels for this classification task are in the `Survived` column of the training data. We split this column into seperate vector for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data.Survived.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the number of observations assigned to each class (i.e. look for the extent of the class imbalance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.4% of passengers are classified as surviving\n"
     ]
    }
   ],
   "source": [
    "survived_fraction = labels.sum() / labels.shape[0]\n",
    "print(f'{survived_fraction:.1%} of passengers are classified as surviving')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spit Dataset into Train and Test Subsets\n",
    "\n",
    "Use stratified sampling to ensure that classes are fairly represented in both train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, y_train, y_test = train_test_split(\n",
    "    data,\n",
    "    labels,\n",
    "    random_state=42,\n",
    "    test_size=0.1,\n",
    "    stratify=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "We will **drop** the following columns from the final set of features:\n",
    "\n",
    "- `PassengerId` - no apparent information content;\n",
    "- `Survived` - i.e. the class labels we wish to predict;\n",
    "- `Name` - no apparent predictive information content;\n",
    "- `Ticket` - no apparent information content; and,\n",
    "- `Cabin` - too many missing values to work with and `Pclass` and `Fare` should be adequate descriptors of cabin.\n",
    "\n",
    "We will need to infer the missing values for the following columns (plus label each observation as having missing data):\n",
    "\n",
    "- `Age` - using `Sex` and whether or not child or adult as inferred from `Name` and `Parch`; and,\n",
    "- `Embarked` - assign to a new category labelled as `UNKNOWN`.\n",
    "\n",
    "We will one-hot-encode the following categorical variables:\n",
    "\n",
    "- `Pclass`;\n",
    "- `Sex`; and,\n",
    "- `Embarked`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data Imputers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_imputer = SimpleImputer(strategy='mean')\n",
    "embarked_imputer = SimpleImputer(strategy='constant', fill_value='UNKNOWN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure and Fit Feature Engineering Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_pipeline = make_column_transformer(\n",
    "    (make_pipeline(age_imputer, StandardScaler()), ['Age']),\n",
    "    (make_pipeline(embarked_imputer, OneHotEncoder()), ['Embarked']),\n",
    "    (StandardScaler(), ['Fare']),\n",
    "    (OneHotEncoder(), ['Pclass', 'Sex']))\n",
    "\n",
    "feature_pipeline.fit(train_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.04511068e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         1.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
       "       [-1.04511068e+00,  1.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  1.00000000e+00,  0.00000000e+00],\n",
       "       [-2.72194763e-16,  0.00000000e+00,  1.00000000e+00, ...,\n",
       "         1.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
       "       ...,\n",
       "       [ 1.32998578e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
       "       [ 1.55983382e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  1.00000000e+00,  0.00000000e+00],\n",
       "       [-9.68494661e-01,  1.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  1.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = feature_pipeline.transform(train_data)\n",
    "X_test = feature_pipeline.transform(test_data)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "We are fairly certain that the final decision boundary needs to be non-linear and that model training will benefit from models that can use weighted loss function. With this in mind, we will test the following model classes:\n",
    "\n",
    "- Support Vector Machines (SVM);\n",
    "- Random Forests (RF);\n",
    "- Gradient Boosting Machine (GBM); and,\n",
    "- Voting Classifier based on combining the above models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Setup\n",
    "\n",
    "We will use 5-fold cross validation for hyper-parameter tuning and then asses performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validator = StratifiedKFold(n_splits=5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Metrics\n",
    "\n",
    "We will use the following metrics to assess model performance:\n",
    "\n",
    "- Area Under ROC Curve (AUC); and,\n",
    "- accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {'auc': roc_auc_score,\n",
    "           'accuray': accuracy_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automation\n",
    "\n",
    "We define a simple class for automating grid-search, cross-validation and metric calculation across all model types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetricScorer = Callable[[Iterable[int], Iterable[int]], float]\n",
    "\n",
    "\n",
    "class MLExperimentRunner:\n",
    "    \"\"\"Model training and metric calculation automation.\"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 metrics: Dict[str, MetricScorer],\n",
    "                 cross_validator: BaseCrossValidator,\n",
    "                 model_selection_metric: str,\n",
    "                 X_train: ndarray,\n",
    "                 y_train: ndarray,\n",
    "                 X_test: ndarray,\n",
    "                 y_test: ndarray,) -> None:\n",
    "        \n",
    "        self.metrics = metrics\n",
    "        self.cv = cross_validator\n",
    "        self.selection_metric = model_selection_metric\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        return None\n",
    "    \n",
    "    def run(self, estimator: BaseEstimator,\n",
    "            param_grid: Dict[str, Any], n_results: int = 10) -> BaseEstimator:\n",
    "        \"\"\"Run an experiment.\"\"\"\n",
    "        \n",
    "        scorers = {name: make_scorer(metric)\n",
    "                   for name, metric in self.metrics.items()}\n",
    "        \n",
    "        experiment = GridSearchCV(\n",
    "            estimator, param_grid, scoring=scorers, cv=self.cv,\n",
    "            refit=self.selection_metric, n_jobs=2)\n",
    "        \n",
    "        experiment.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        self._display_results(experiment.cv_results_, n_results)\n",
    "        self._display_test_metrics(experiment.best_estimator_)\n",
    "        \n",
    "        return experiment.best_estimator_\n",
    "\n",
    "    def _display_test_metrics(self, estimator: BaseEstimator) -> None:\n",
    "        \"\"\"Print metrics for test data to stdout.\"\"\"\n",
    "        \n",
    "        predictions = estimator.predict(self.X_test)\n",
    "        results = {\n",
    "            metric_name: metric_func(predictions, self.y_test)\n",
    "            for metric_name, metric_func in self.metrics.items()}\n",
    "        \n",
    "        print('----------------------------------------')\n",
    "        print('-- TEST DATA METRICS (best estimator) --')\n",
    "        print('---------------------------------------')\n",
    "        for metric_name, metric_value in results.items():\n",
    "            print(f'{metric_name}: {metric_value:.4f}')\n",
    "        print('----------------------------------------')\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def _display_results(self, cv_results: Dict[str, Any],\n",
    "                         n_results: int) -> None:\n",
    "        \"\"\"Display cross validation results as DataFrame.\"\"\"\n",
    "        \n",
    "        cv_data = DataFrame(cv_results)\n",
    "\n",
    "        metric_col_names = [\n",
    "            e \n",
    "            for name in self.metrics.keys()\n",
    "            for e in [f'mean_test_{name}', f'std_test_{name}']]\n",
    "\n",
    "        selection_metric_col_name = f'mean_test_{self.selection_metric}'\n",
    "\n",
    "        cv_data.sort_values(\n",
    "            by=selection_metric_col_name, ascending=False, inplace=True)\n",
    "        cv_data.reset_index(inplace=True)\n",
    "\n",
    "        display(cv_data[['params'] + metric_col_names].head(n_results))\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we then generate an instance of the experiment runner for the current task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_experiment = MLExperimentRunner(\n",
    "    metrics, cross_validator, 'auc', X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_auc</th>\n",
       "      <th>std_test_auc</th>\n",
       "      <th>mean_test_accuray</th>\n",
       "      <th>std_test_accuray</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'C': 100, 'kernel': 'rbf'}</td>\n",
       "      <td>0.790843</td>\n",
       "      <td>0.030378</td>\n",
       "      <td>0.805243</td>\n",
       "      <td>0.028932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'C': 10, 'kernel': 'rbf'}</td>\n",
       "      <td>0.787953</td>\n",
       "      <td>0.039333</td>\n",
       "      <td>0.803995</td>\n",
       "      <td>0.037089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'C': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.778869</td>\n",
       "      <td>0.032124</td>\n",
       "      <td>0.792759</td>\n",
       "      <td>0.030329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'C': 0.1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.770731</td>\n",
       "      <td>0.031651</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.030487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'C': 0.1, 'kernel': 'linear'}</td>\n",
       "      <td>0.770090</td>\n",
       "      <td>0.034818</td>\n",
       "      <td>0.790262</td>\n",
       "      <td>0.034360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "      <td>0.770090</td>\n",
       "      <td>0.034818</td>\n",
       "      <td>0.790262</td>\n",
       "      <td>0.034360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'C': 10, 'kernel': 'linear'}</td>\n",
       "      <td>0.770090</td>\n",
       "      <td>0.034818</td>\n",
       "      <td>0.790262</td>\n",
       "      <td>0.034360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'C': 100, 'kernel': 'linear'}</td>\n",
       "      <td>0.770090</td>\n",
       "      <td>0.034818</td>\n",
       "      <td>0.790262</td>\n",
       "      <td>0.034360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'C': 0.01, 'kernel': 'linear'}</td>\n",
       "      <td>0.769075</td>\n",
       "      <td>0.034437</td>\n",
       "      <td>0.789014</td>\n",
       "      <td>0.034277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'C': 0.01, 'kernel': 'rbf'}</td>\n",
       "      <td>0.522359</td>\n",
       "      <td>0.021938</td>\n",
       "      <td>0.594257</td>\n",
       "      <td>0.064600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            params  mean_test_auc  std_test_auc  \\\n",
       "0      {'C': 100, 'kernel': 'rbf'}       0.790843      0.030378   \n",
       "1       {'C': 10, 'kernel': 'rbf'}       0.787953      0.039333   \n",
       "2        {'C': 1, 'kernel': 'rbf'}       0.778869      0.032124   \n",
       "3      {'C': 0.1, 'kernel': 'rbf'}       0.770731      0.031651   \n",
       "4   {'C': 0.1, 'kernel': 'linear'}       0.770090      0.034818   \n",
       "5     {'C': 1, 'kernel': 'linear'}       0.770090      0.034818   \n",
       "6    {'C': 10, 'kernel': 'linear'}       0.770090      0.034818   \n",
       "7   {'C': 100, 'kernel': 'linear'}       0.770090      0.034818   \n",
       "8  {'C': 0.01, 'kernel': 'linear'}       0.769075      0.034437   \n",
       "9     {'C': 0.01, 'kernel': 'rbf'}       0.522359      0.021938   \n",
       "\n",
       "   mean_test_accuray  std_test_accuray  \n",
       "0           0.805243          0.028932  \n",
       "1           0.803995          0.037089  \n",
       "2           0.792759          0.030329  \n",
       "3           0.786517          0.030487  \n",
       "4           0.790262          0.034360  \n",
       "5           0.790262          0.034360  \n",
       "6           0.790262          0.034360  \n",
       "7           0.790262          0.034360  \n",
       "8           0.789014          0.034277  \n",
       "9           0.594257          0.064600  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "-- TEST DATA METRICS (best estimator) --\n",
      "---------------------------------------\n",
      "auc: 0.7784\n",
      "accuray: 0.7889\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "svm_model = ml_experiment.run(\n",
    "    SVC(class_weight='balanced', gamma='auto', probability=True),\n",
    "    {'C': [0.01, 0.1, 1, 10, 100],\n",
    "     'kernel': ['linear', 'rbf']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_auc</th>\n",
       "      <th>std_test_auc</th>\n",
       "      <th>mean_test_accuray</th>\n",
       "      <th>std_test_accuray</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>0.828182</td>\n",
       "      <td>0.027416</td>\n",
       "      <td>0.845194</td>\n",
       "      <td>0.024508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 4, 'n_e...</td>\n",
       "      <td>0.826142</td>\n",
       "      <td>0.029978</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.026080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 4, 'n_e...</td>\n",
       "      <td>0.825143</td>\n",
       "      <td>0.025284</td>\n",
       "      <td>0.841448</td>\n",
       "      <td>0.021473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 2, 'n_e...</td>\n",
       "      <td>0.824505</td>\n",
       "      <td>0.032608</td>\n",
       "      <td>0.841448</td>\n",
       "      <td>0.028152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 10, 'min_samples_split': 6, 'n_e...</td>\n",
       "      <td>0.823895</td>\n",
       "      <td>0.030275</td>\n",
       "      <td>0.841448</td>\n",
       "      <td>0.026197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 4, 'n_es...</td>\n",
       "      <td>0.823713</td>\n",
       "      <td>0.027507</td>\n",
       "      <td>0.838951</td>\n",
       "      <td>0.022889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 4, 'n_es...</td>\n",
       "      <td>0.822480</td>\n",
       "      <td>0.027492</td>\n",
       "      <td>0.838951</td>\n",
       "      <td>0.024386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'max_depth': 8, 'min_samples_split': 2, 'n_es...</td>\n",
       "      <td>0.822096</td>\n",
       "      <td>0.028564</td>\n",
       "      <td>0.837703</td>\n",
       "      <td>0.026750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 6, 'n...</td>\n",
       "      <td>0.822086</td>\n",
       "      <td>0.028906</td>\n",
       "      <td>0.837703</td>\n",
       "      <td>0.024777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 4, 'n...</td>\n",
       "      <td>0.822080</td>\n",
       "      <td>0.026496</td>\n",
       "      <td>0.837703</td>\n",
       "      <td>0.021716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  mean_test_auc  \\\n",
       "0  {'max_depth': 10, 'min_samples_split': 2, 'n_e...       0.828182   \n",
       "1  {'max_depth': 10, 'min_samples_split': 4, 'n_e...       0.826142   \n",
       "2  {'max_depth': 10, 'min_samples_split': 4, 'n_e...       0.825143   \n",
       "3  {'max_depth': 10, 'min_samples_split': 2, 'n_e...       0.824505   \n",
       "4  {'max_depth': 10, 'min_samples_split': 6, 'n_e...       0.823895   \n",
       "5  {'max_depth': 8, 'min_samples_split': 4, 'n_es...       0.823713   \n",
       "6  {'max_depth': 8, 'min_samples_split': 4, 'n_es...       0.822480   \n",
       "7  {'max_depth': 8, 'min_samples_split': 2, 'n_es...       0.822096   \n",
       "8  {'max_depth': None, 'min_samples_split': 6, 'n...       0.822086   \n",
       "9  {'max_depth': None, 'min_samples_split': 4, 'n...       0.822080   \n",
       "\n",
       "   std_test_auc  mean_test_accuray  std_test_accuray  \n",
       "0      0.027416           0.845194          0.024508  \n",
       "1      0.029978           0.842697          0.026080  \n",
       "2      0.025284           0.841448          0.021473  \n",
       "3      0.032608           0.841448          0.028152  \n",
       "4      0.030275           0.841448          0.026197  \n",
       "5      0.027507           0.838951          0.022889  \n",
       "6      0.027492           0.838951          0.024386  \n",
       "7      0.028564           0.837703          0.026750  \n",
       "8      0.028906           0.837703          0.024777  \n",
       "9      0.026496           0.837703          0.021716  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "-- TEST DATA METRICS (best estimator) --\n",
      "---------------------------------------\n",
      "auc: 0.8256\n",
      "accuray: 0.8333\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rf_model = ml_experiment.run(\n",
    "    RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "    {'n_estimators': [10, 100, 1000],\n",
    "     'min_samples_split': [2, 4, 6, 8, 10],\n",
    "     'max_depth': [2, 4, 6, 8, 10, None]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_auc</th>\n",
       "      <th>std_test_auc</th>\n",
       "      <th>mean_test_accuray</th>\n",
       "      <th>std_test_accuray</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 4, 'min_sa...</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.038088</td>\n",
       "      <td>0.838951</td>\n",
       "      <td>0.031344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'min_sa...</td>\n",
       "      <td>0.821754</td>\n",
       "      <td>0.045520</td>\n",
       "      <td>0.838951</td>\n",
       "      <td>0.036210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'min_sa...</td>\n",
       "      <td>0.820127</td>\n",
       "      <td>0.042660</td>\n",
       "      <td>0.837703</td>\n",
       "      <td>0.034516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'min_sa...</td>\n",
       "      <td>0.819740</td>\n",
       "      <td>0.040412</td>\n",
       "      <td>0.836454</td>\n",
       "      <td>0.032256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'min_sa...</td>\n",
       "      <td>0.819740</td>\n",
       "      <td>0.040412</td>\n",
       "      <td>0.836454</td>\n",
       "      <td>0.032256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'min_sa...</td>\n",
       "      <td>0.819740</td>\n",
       "      <td>0.040412</td>\n",
       "      <td>0.836454</td>\n",
       "      <td>0.032256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 4, 'min_sa...</td>\n",
       "      <td>0.819560</td>\n",
       "      <td>0.039930</td>\n",
       "      <td>0.837703</td>\n",
       "      <td>0.032984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 4, 'min_sa...</td>\n",
       "      <td>0.817325</td>\n",
       "      <td>0.041290</td>\n",
       "      <td>0.836454</td>\n",
       "      <td>0.036011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'min_s...</td>\n",
       "      <td>0.816318</td>\n",
       "      <td>0.031692</td>\n",
       "      <td>0.835206</td>\n",
       "      <td>0.026700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'min_s...</td>\n",
       "      <td>0.816085</td>\n",
       "      <td>0.041838</td>\n",
       "      <td>0.836454</td>\n",
       "      <td>0.034097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  mean_test_auc  \\\n",
       "0  {'learning_rate': 0.1, 'max_depth': 4, 'min_sa...       0.822430   \n",
       "1  {'learning_rate': 0.1, 'max_depth': 2, 'min_sa...       0.821754   \n",
       "2  {'learning_rate': 0.1, 'max_depth': 2, 'min_sa...       0.820127   \n",
       "3  {'learning_rate': 0.1, 'max_depth': 2, 'min_sa...       0.819740   \n",
       "4  {'learning_rate': 0.1, 'max_depth': 2, 'min_sa...       0.819740   \n",
       "5  {'learning_rate': 0.1, 'max_depth': 2, 'min_sa...       0.819740   \n",
       "6  {'learning_rate': 0.1, 'max_depth': 4, 'min_sa...       0.819560   \n",
       "7  {'learning_rate': 0.1, 'max_depth': 4, 'min_sa...       0.817325   \n",
       "8  {'learning_rate': 0.01, 'max_depth': 4, 'min_s...       0.816318   \n",
       "9  {'learning_rate': 0.01, 'max_depth': 4, 'min_s...       0.816085   \n",
       "\n",
       "   std_test_auc  mean_test_accuray  std_test_accuray  \n",
       "0      0.038088           0.838951          0.031344  \n",
       "1      0.045520           0.838951          0.036210  \n",
       "2      0.042660           0.837703          0.034516  \n",
       "3      0.040412           0.836454          0.032256  \n",
       "4      0.040412           0.836454          0.032256  \n",
       "5      0.040412           0.836454          0.032256  \n",
       "6      0.039930           0.837703          0.032984  \n",
       "7      0.041290           0.836454          0.036011  \n",
       "8      0.031692           0.835206          0.026700  \n",
       "9      0.041838           0.836454          0.034097  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "-- TEST DATA METRICS (best estimator) --\n",
      "---------------------------------------\n",
      "auc: 0.8044\n",
      "accuray: 0.8111\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "gbm_model = ml_experiment.run(\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    {'n_estimators': [10, 100, 1000],\n",
    "     'learning_rate': [0.01, 0.1, 1, 10],\n",
    "     'min_samples_split': [2, 4, 6, 8, 10],\n",
    "     'max_depth': [2, 4, 8, 10, None]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_auc</th>\n",
       "      <th>std_test_auc</th>\n",
       "      <th>mean_test_accuray</th>\n",
       "      <th>std_test_accuray</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'voting': 'hard'}</td>\n",
       "      <td>0.820606</td>\n",
       "      <td>0.032044</td>\n",
       "      <td>0.838951</td>\n",
       "      <td>0.026112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'voting': 'soft'}</td>\n",
       "      <td>0.815900</td>\n",
       "      <td>0.033738</td>\n",
       "      <td>0.837703</td>\n",
       "      <td>0.029198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               params  mean_test_auc  std_test_auc  mean_test_accuray  \\\n",
       "0  {'voting': 'hard'}       0.820606      0.032044           0.838951   \n",
       "1  {'voting': 'soft'}       0.815900      0.033738           0.837703   \n",
       "\n",
       "   std_test_accuray  \n",
       "0          0.026112  \n",
       "1          0.029198  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "-- TEST DATA METRICS (best estimator) --\n",
      "---------------------------------------\n",
      "auc: 0.8256\n",
      "accuray: 0.8333\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "voting_model = ml_experiment.run(\n",
    "    VotingClassifier([\n",
    "        ('svm', svm_model), ('rf', rf_model), ('gbm', gbm_model)]),\n",
    "    {'voting': ['hard', 'soft']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble Final Prediction Pipeline\n",
    "\n",
    "We will choose the random forest model to combine with the feature pipeline and then persist to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_pipeline = make_pipeline(feature_pipeline, rf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Fit Model on Entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('columntransformer', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('pipeline-1', Pipeline(memory=None,\n",
       "     steps=[('simpleimputer', SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mea...tors=1000, n_jobs=None, oob_score=False,\n",
       "            random_state=42, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_pipeline.fit(data, data.Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_pipeline.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/titanic-ml-2019-02-11T16:38:12.joblib']"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_name = 'titanic-ml'\n",
    "directory = 'models'\n",
    "timestamp = datetime.now().isoformat(timespec='seconds')\n",
    "\n",
    "joblib.dump(prediction_pipeline, \n",
    "            f'{directory}/{base_model_name}-{timestamp}.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
